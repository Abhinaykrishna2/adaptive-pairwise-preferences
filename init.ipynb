{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "def load_data(movies_file, ratings_file):\n",
    "    movies = pd.read_csv(movies_file)\n",
    "    ratings = pd.read_csv(ratings_file)\n",
    "    \n",
    "    # Create the user-item matrix\n",
    "    user_item_matrix = ratings.pivot(index='User_ID', columns='Movie_ID', values='Rating')\n",
    "    # Fill missing values (here we fill with 0)\n",
    "    user_item_matrix.fillna(0, inplace=True)\n",
    "    sparse_user_item = csr_matrix(user_item_matrix.values)\n",
    "    return movies, ratings, user_item_matrix, sparse_user_item\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Module 2: Factor Model Training and Bias Computation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import TruncatedSVD\n",
    "import numpy as np\n",
    "\n",
    "def train_factor_model(sparse_user_item, n_components=30):\n",
    "    svd = TruncatedSVD(n_components=n_components, random_state=42)\n",
    "    user_factors = svd.fit_transform(sparse_user_item)  # shape: (num_users, n_components)\n",
    "    movie_factors = svd.components_.T                    # shape: (num_movies, n_components)\n",
    "    return user_factors, movie_factors, svd\n",
    "\n",
    "def compute_biases(user_item_matrix):\n",
    "    # Global bias: mean of all nonzero ratings.\n",
    "    all_ratings = user_item_matrix.values[user_item_matrix.values != 0]\n",
    "    global_bias = all_ratings.mean()\n",
    "    # Movie biases: average deviation per movie (only on nonzero ratings)\n",
    "    movie_biases = user_item_matrix.replace(0, pd.NA).mean() - global_bias\n",
    "    # User biases (if needed)\n",
    "    user_biases = user_item_matrix.replace(0, pd.NA).mean(axis=1) - global_bias\n",
    "    return global_bias, movie_biases, user_biases\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import norm\n",
    "\n",
    "def phi(x):\n",
    "    \"\"\"Standard normal PDF.\"\"\"\n",
    "    return norm.pdf(x)\n",
    "\n",
    "def Phi(x):\n",
    "    \"\"\"Standard normal CDF.\"\"\"\n",
    "    return norm.cdf(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Module 4: Pairwise Preference Model & Information Gain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_delta(mu, Sigma, v_l, v_r, b_il, b_ir):\n",
    "    \"\"\"\n",
    "    Compute:\n",
    "      delta = (b_il - b_ir + (v_l - v_r)^T mu) / s_lr\n",
    "    where s_lr = sqrt( v_l^T Sigma v_l + v_r^T Sigma v_r ).\n",
    "    \"\"\"\n",
    "    v_diff = v_l - v_r\n",
    "    num = (b_il - b_ir) + np.dot(v_diff, mu)\n",
    "    s_lr = np.sqrt(np.dot(v_l, np.dot(Sigma, v_l)) + np.dot(v_r, np.dot(Sigma, v_r)) + 1e-8)\n",
    "    return num / s_lr, s_lr, v_diff\n",
    "\n",
    "def information_gain(mu, Sigma, v_l, v_r, b_il, b_ir):\n",
    "    \"\"\"\n",
    "    Computes the IG criterion:\n",
    "      IG = log( 1 + (1/s_lr^2) * (phi(delta)^2/(Phi(delta)(1-Phi(delta))) *\n",
    "             (v_l - v_r)^T Sigma (v_l - v_r) ) )\n",
    "    \"\"\"\n",
    "    delta, s_lr, v_diff = compute_delta(mu, Sigma, v_l, v_r, b_il, b_ir)\n",
    "    Phi_delta = np.clip(Phi(delta), 1e-6, 1-1e-6)\n",
    "    term = (phi(delta)**2) / (Phi_delta * (1 - Phi_delta))\n",
    "    ig = np.log(1 + (1.0/(s_lr**2)) * term * np.dot(v_diff, np.dot(Sigma, v_diff)))\n",
    "    return ig\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Module 5: Heuristic Candidate Filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def popularity_filter(candidate_ids, movie_popularity, pop_threshold):\n",
    "    \"\"\"Keep only movies with a rating count above the threshold.\"\"\"\n",
    "    return [mid for mid in candidate_ids if movie_popularity.get(mid, 0) >= pop_threshold]\n",
    "\n",
    "def like_filter(candidate_ids, user_vector, movie_factors, movie_ids, topk):\n",
    "    \"\"\"\n",
    "    Keep only the top-k movies predicted to be liked by the user.\n",
    "    Predicted score is computed as the dot product between the movie factor and user_vector.\n",
    "    \"\"\"\n",
    "    scores = {}\n",
    "    for mid in candidate_ids:\n",
    "        idx = movie_ids.index(mid)\n",
    "        scores[mid] = np.dot(movie_factors[idx], user_vector)\n",
    "    sorted_candidates = sorted(candidate_ids, key=lambda m: scores[m], reverse=True)\n",
    "    return sorted_candidates[:topk]\n",
    "\n",
    "def used_filter(candidate_ids, used_ids):\n",
    "    \"\"\"Remove movies that have been used in previous comparisons.\"\"\"\n",
    "    return [mid for mid in candidate_ids if mid not in used_ids]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Module 6: EP Update (Surrogate via Local Laplace Approximation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy.linalg import inv\n",
    "\n",
    "def ep_update(mu, Sigma, v_l, v_r, b_il, b_ir, response):\n",
    "    \"\"\"\n",
    "    Perform one surrogate EP update.\n",
    "    \n",
    "    response = 1 if the user prefers movie l over r; else 0.\n",
    "    \n",
    "    Compute:\n",
    "      delta = (b_il - b_ir + (v_l - v_r)^T mu) / s,   where s = sqrt(v_l^T Sigma v_l + v_r^T Sigma v_r)\n",
    "    Then:\n",
    "      For response==1, use:\n",
    "         g = (phi(delta)/Phi(delta))*(x/s)\n",
    "         lambda = (phi(delta)/Phi(delta))*((phi(delta)/Phi(delta)) + delta)/(s^2)\n",
    "      For response==0, flip the sign.\n",
    "      \n",
    "    Update:\n",
    "      mu_new = mu + Sigma @ g\n",
    "      Sigma_new = inv(inv(Sigma) + lambda * np.outer(x, x))\n",
    "    \"\"\"\n",
    "    delta, s, x = compute_delta(mu, Sigma, v_l, v_r, b_il, b_ir)\n",
    "    if response == 0:\n",
    "        delta = -delta  # flip for the opposite preference\n",
    "\n",
    "    psi = phi(delta)\n",
    "    Phi_val = np.clip(Phi(delta), 1e-6, 1-1e-6)\n",
    "    \n",
    "    if response == 1:\n",
    "        g = (psi / Phi_val) * (x / s)\n",
    "        lambda_val = (psi / Phi_val) * ((psi / Phi_val) + delta) / (s**2)\n",
    "    else:\n",
    "        g = -(psi / (1 - Phi_val)) * (x / s)\n",
    "        lambda_val = (psi / (1 - Phi_val)) * ((psi / (1 - Phi_val)) - delta) / (s**2)\n",
    "    \n",
    "    mu_new = mu + Sigma @ g\n",
    "    Sigma_inv = inv(Sigma)\n",
    "    Sigma_new = inv(Sigma_inv + lambda_val * np.outer(x, x))\n",
    "    return mu_new, Sigma_new\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Module 7: Static Adaptive Pairwise Feedback Simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def static_pairwise_update(user_id, user_item_matrix, movie_factors, movie_biases,\n",
    "                           user_factors, movie_ids, movie_popularity,\n",
    "                           num_queries=1, pop_threshold=1000, topk=50):\n",
    "    \"\"\"\n",
    "    Perform a static simulation of the adaptive pairwise feedback procedure.\n",
    "    \n",
    "    Instead of an interactive loop, we use the static ratings data to\n",
    "    simulate a fixed number (num_queries) of pairwise updates.\n",
    "    \n",
    "    Returns the final estimated user latent vector (posterior mean) and feedback history.\n",
    "    \"\"\"\n",
    "    # Initialize user posterior using the factor model (using sample mean and covariance)\n",
    "    mu0 = user_factors.mean(axis=0)\n",
    "    Sigma0 = np.cov(user_factors.T) + 1e-6 * np.eye(user_factors.shape[1])\n",
    "    mu, Sigma = mu0.copy(), Sigma0.copy()\n",
    "    \n",
    "    # Use movies that the user has rated (nonzero entries)\n",
    "    user_ratings = user_item_matrix.loc[user_id]\n",
    "    candidate_ids = user_ratings[user_ratings > 0].index.tolist()\n",
    "    used_ids = set()\n",
    "    feedback_history = []\n",
    "    \n",
    "    for q in range(num_queries):\n",
    "        # Apply candidate filters\n",
    "        filtered_ids = popularity_filter(candidate_ids, movie_popularity, pop_threshold)\n",
    "        filtered_ids = like_filter(filtered_ids, mu, movie_factors, movie_ids, topk)\n",
    "        filtered_ids = used_filter(filtered_ids, used_ids)\n",
    "        \n",
    "        if len(filtered_ids) < 2:\n",
    "            print(f\"Not enough candidates after filtering at query {q+1}\")\n",
    "            break\n",
    "        \n",
    "        # For simplicity, evaluate IG for adjacent pairs in sorted order\n",
    "        scores = {}\n",
    "        for mid in filtered_ids:\n",
    "            idx = movie_ids.index(mid)\n",
    "            scores[mid] = movie_biases[mid] + np.dot(movie_factors[idx], mu)\n",
    "        \n",
    "        sorted_ids = sorted(filtered_ids, key=lambda m: scores[m])\n",
    "        best_ig = -np.inf\n",
    "        best_pair = None\n",
    "        for i in range(len(sorted_ids)-1):\n",
    "            m1 = sorted_ids[i]\n",
    "            m2 = sorted_ids[i+1]\n",
    "            idx1 = movie_ids.index(m1)\n",
    "            idx2 = movie_ids.index(m2)\n",
    "            ig = information_gain(mu, Sigma, movie_factors[idx1], movie_factors[idx2],\n",
    "                                  movie_biases[m1], movie_biases[m2])\n",
    "            if ig > best_ig:\n",
    "                best_ig = ig\n",
    "                best_pair = (m1, m2)\n",
    "        \n",
    "        if best_pair is None:\n",
    "            break\n",
    "        \n",
    "        movie_A, movie_B = best_pair\n",
    "        used_ids.update(best_pair)\n",
    "        \n",
    "        # Simulate the user response from the static ratings:\n",
    "        true_rating_A = user_item_matrix.loc[user_id, movie_A]\n",
    "        true_rating_B = user_item_matrix.loc[user_id, movie_B]\n",
    "        response = 1 if true_rating_A >= true_rating_B else 0\n",
    "        \n",
    "        feedback_history.append({\n",
    "            'query': q+1,\n",
    "            'movie_A': movie_A,\n",
    "            'movie_B': movie_B,\n",
    "            'true_rating_A': true_rating_A,\n",
    "            'true_rating_B': true_rating_B,\n",
    "            'response': response,\n",
    "            'IG': best_ig\n",
    "        })\n",
    "        print(f\"Static Query {q+1}: {movie_A} vs. {movie_B} -> Response: {'A' if response==1 else 'B'} (IG={best_ig:.4f})\")\n",
    "        \n",
    "        # Update the user latent vector using the EP update module.\n",
    "        idx_A = movie_ids.index(movie_A)\n",
    "        idx_B = movie_ids.index(movie_B)\n",
    "        mu, Sigma = ep_update(mu, Sigma,\n",
    "                              movie_factors[idx_A], movie_factors[idx_B],\n",
    "                              movie_biases[movie_A], movie_biases[movie_B],\n",
    "                              response)\n",
    "        \n",
    "        # Optionally relax the popularity threshold after each query.\n",
    "        pop_threshold = max(0, pop_threshold - 50)\n",
    "    \n",
    "    return mu, Sigma, feedback_history\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Module 8: Recommendation Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_recommendations(mu, movie_factors, movie_biases, movie_ids, top_n=10):\n",
    "    scores = []\n",
    "    for mid in movie_ids:\n",
    "        idx = movie_ids.index(mid)\n",
    "        # Predicted rating: movie bias + dot(user latent, movie latent)\n",
    "        score = movie_biases[mid] + np.dot(movie_factors[idx], mu)\n",
    "        scores.append((mid, score))\n",
    "    scores.sort(key=lambda x: x[1], reverse=True)\n",
    "    recommended = [mid for mid, score in scores[:top_n]]\n",
    "    return recommended\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected User ID: 386900\n",
      "Static Query 1: 241 vs. 4266 -> Response: A (IG=0.5602)\n",
      "Static Query 2: 2612 vs. 3150 -> Response: A (IG=0.5136)\n",
      "Static Query 3: 1466 vs. 197 -> Response: B (IG=0.4855)\n",
      "Static Query 4: 501 vs. 4402 -> Response: A (IG=0.4681)\n",
      "Static Query 5: 2395 vs. 32 -> Response: A (IG=0.4856)\n",
      "\n",
      "Final estimated user latent vector (mu):\n",
      "[25.26709556 -0.79209306  0.71748474 -0.88099476 -1.46448787 -1.40831392\n",
      "  0.0342057   0.77313304 -1.19099873 -0.18078485 -1.49405127  0.74528173\n",
      "  1.40268965 -0.26208274 -0.66413475 -0.20076085  0.57038783  0.13262089\n",
      " -0.12291194  1.18911257  0.59295636  0.62111004 -0.3628359  -0.87968049\n",
      " -0.68870719  0.54098492 -0.72611832  0.67556544  0.25877973 -0.17676838]\n",
      "\n",
      "Feedback History:\n",
      "{'query': 1, 'movie_A': 241, 'movie_B': 4266, 'true_rating_A': np.float64(5.0), 'true_rating_B': np.float64(5.0), 'response': 1, 'IG': np.float64(0.5602033091256166)}\n",
      "{'query': 2, 'movie_A': 2612, 'movie_B': 3150, 'true_rating_A': np.float64(2.0), 'true_rating_B': np.float64(1.0), 'response': 1, 'IG': np.float64(0.5136134111056061)}\n",
      "{'query': 3, 'movie_A': 1466, 'movie_B': 197, 'true_rating_A': np.float64(2.0), 'true_rating_B': np.float64(3.0), 'response': 0, 'IG': np.float64(0.48550050373025916)}\n",
      "{'query': 4, 'movie_A': 501, 'movie_B': 4402, 'true_rating_A': np.float64(5.0), 'true_rating_B': np.float64(5.0), 'response': 1, 'IG': np.float64(0.4680942611134977)}\n",
      "{'query': 5, 'movie_A': 2395, 'movie_B': 32, 'true_rating_A': np.float64(5.0), 'true_rating_B': np.float64(5.0), 'response': 1, 'IG': np.float64(0.4855632309646534)}\n",
      "\n",
      "Top recommended movies for user 386900 : ['The Sixth Sense', 'The Silence of the Lambs', 'Pirates of the Caribbean: The Curse of the Black Pearl', 'Finding Nemo (Widescreen)', 'Lord of the Rings: The Fellowship of the Ring']\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "movies_file = 'data/Netflix_Dataset_Movie.csv'\n",
    "ratings_file = 'data/Netflix_Dataset_Rating.csv'\n",
    "\n",
    "# Module 1: Load data\n",
    "movies, ratings, user_item_matrix, sparse_user_item = load_data(movies_file, ratings_file)\n",
    "\n",
    "# Module 2: Train factor model and compute bias\n",
    "user_factors, movie_factors, svd_model = train_factor_model(sparse_user_item, n_components=30)\n",
    "global_bias, movie_biases_series, user_biases_series = compute_biases(user_item_matrix)\n",
    "movie_biases = {mid: movie_biases_series[mid] for mid in movie_biases_series.index.tolist()}\n",
    "movie_ids = user_item_matrix.columns.tolist()\n",
    "\n",
    "movie_popularity = ratings.groupby('Movie_ID').size().to_dict()\n",
    "\n",
    "available_user_ids = user_item_matrix.index.tolist()\n",
    "user_id = random.choice(available_user_ids)\n",
    "print(\"Selected User ID:\", user_id)\n",
    "\n",
    "# Module 7: Run a static pairwise feedback simulation\n",
    "final_mu, final_Sigma, feedback_history = static_pairwise_update(\n",
    "    user_id, user_item_matrix, movie_factors, movie_biases,\n",
    "    user_factors, movie_ids, movie_popularity,\n",
    "    num_queries=5,   \n",
    "    pop_threshold=1000,\n",
    "    topk=50\n",
    ")\n",
    "\n",
    "# Module 8: Generate recommendations with the updated latent vector\n",
    "recommended_ids = generate_recommendations(final_mu, movie_factors, movie_biases, movie_ids, top_n=5)\n",
    "\n",
    "recommended_movies = movies[movies['Movie_ID'].isin(recommended_ids)]\n",
    "recommended_movies = recommended_movies.set_index('Movie_ID').loc[recommended_ids]\n",
    "recommended_names = recommended_movies['Name'].tolist()\n",
    "\n",
    "print(\"\\nFinal estimated user latent vector (mu):\")\n",
    "print(final_mu)\n",
    "print(\"\\nFeedback History:\")\n",
    "for fb in feedback_history:\n",
    "    print(fb)\n",
    "print(\"\\nTop recommended movies for user\", user_id, \":\", recommended_names)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MLpaper",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
